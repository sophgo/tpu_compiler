# python_tools

## overview

A collection of python tools for debugging. The MLIR TPU dialect tensor saving and loading are based on npy and npz file format, which can be easily manipulated by python numpy functions. npz file is just zip of a bunch of npy files, we can just run `unzip` to save a npz into separate npy files.

## CVI npz utilites commands

* compare
Compare two npz tensor files.

positional arguments:
  target_file           Comparing target file
  ref_file              Comparing reference file

optional arguments:
  -h, --help            show this help message and exit
  --verbose, -v
  --discard, -d
  --dtype DTYPE         force dtype
  --tolerance TOLERANCE
                        tolerance for cos/cor/euclid similarity
  --op_info OP_INFO     A csv file op_info, including order and dequant
                        threshold
  --dequant             Do dequantization flag, use threshold table provided
                        in --op_info
  --order ORDER         A csv file containing order of the tensors, used when
                        --op_info is not present
  --tensor TENSOR       Compare one specific tensor by name
  --excepts EXCEPTS     List of tensors except from comparing
  --full-array          Dump full array data when comparing failed
  --stats_int8_tensor   Do statistics on int8 tensor for saturate ratio and
                        low ratio
  --save SAVE           Save result as a csv file

```
python cvi_npz_tool.py compare [-h] [--verbose] [--discard]
                       [--dtype DTYPE]
                       [--tolerance TOLERANCE] [--op_info OP_INFO] [--dequant]
                       [--order ORDER] [--tensor TENSOR] [--excepts EXCEPTS]
                       [--full-array] [--stats_int8_tensor] [--save SAVE]
                       target_file ref_file
```

* rename

Rename one array in npz.

```
$ python rename in.npz name1 name2
```

* extract

Extract multiple array from npz file to another npz file
```
$ python extract in.npz out.npz arr1,arr2,arr3
```

*  dump

Dump one array from the npz file. Show top-k if [K] is provided.
```
$ python cvi_npz_tool.py dump file.npz arrayname [K]
```

* to_bin

Save one array from the npz file into a binary file.
```
$ python cvi_npz_tool.py to_bin file.npz arrayname
```

* bf16_to_fp32

convert npz each array from bfloat16 type to float32

```
$python cvi_npz_tool.py bf16_to_fp32 in.npz out.npz
```

## caffe commands

The blobs dump will dump all final blob data. However, intermidiate results of inplace computation are overwriten. To workaround, to edit the deploy.prototxt manually, unfold the inplace nodes.

Run inference with fp32 model. If `--dump_weight` is provided, a weight npz file is generated, which should be identical with the weight npz generated by mlir-translate.

To match the previous input/output data. Feed input data with `--force-input` argument.

```
$ run_caffe_classifier.py \
    --model_def $MODEL_PATH/caffe/ResNet-50-deploy.prototxt \
    --pretrained_model $MODEL_PATH/caffe/ResNet-50-model.caffemodel \
    --mean_file $PYTHON_TOOLS_PATH/data/ilsvrc_2012_mean.npy \
    --label_file $PYTHON_TOOLS_PATH/data/ilsvrc12/synset_words.txt \
    --dump_blobs resnet50_blobs.npz \
    $PYTHON_TOOLS_PATH/data/images/cat.jpg \
    caffe_out.npy

$ bin_to_npy.py $DATA_PATH/test_cat_in_fp32.bin float32 1 3 224 224 \
    resnet50_input_fp32.npy
$ run_caffe_classifier.py \
    --model_def $MODEL_PATH/caffe/ResNet-50-deploy.prototxt \
    --pretrained_model $MODEL_PATH/caffe/ResNet-50-model.caffemodel \
    --mean_file $PYTHON_TOOLS_PATH/data/ilsvrc_2012_mean.npy \
    --label_file $PYTHON_TOOLS_PATH/data/ilsvrc12/synset_words.txt \
    --dump_blobs resnet50_blobs.npz \
    $PYTHON_TOOLS_PATH/data/images/cat.jpg \
    caffe_out.npy
$ bin_compare.py caffe_out.bin $DATA_PATH/test_cat_out_resnet50_prob_fp32.bin \
    float32 1 1 1 1000 5
```

mobilenet-v2
```
$ run_caffe_classifier.py \
    --model_def $MODEL_PATH/caffe/mobilenet_v2_deploy.prototxt \
    --pretrained_model $MODEL_PATH/caffe/mobilenet_v2.caffemodel \
    --mean 103.94,116.78,123.68 \
    --input_scale 0.017 \
    --label_file $PYTHON_TOOLS_PATH/data/ilsvrc12/synset_words.txt \
    --dump_blobs mobilenet_v2_blobs.npz \
    $PYTHON_TOOLS_PATH/data/images/cat.jpg \
    caffe_out.npy
```

yolo-v3
```
$ run_caffe_detector_yolo.py \
    --model_def $MODEL_PATH/caffe/yolov3/416/yolov3_416.prototxt \
    --pretrained_model $MODEL_PATH/caffe/yolov3/416/yolov3_416.caffemodel \
    --net_input_dims 416,416 \
    --obj_threshold 0.3 \
    --nms_threshold 0.5 \
    --dump_blobs yolov3_blobs.npz \
    --input_file $PYTHON_TOOLS_PATH/data/yolo/dog.jpg \
    --label_file $PYTHON_TOOLS_PATH/data/coco-labels-2014_2017.txt \
    --draw_image out.jpg
$ feh out.jpg
```

```
$ eval_caffe_detector_yolo.py \
    --model_def $MODEL_PATH/caffe/yolov3/416/yolov3_416.prototxt \
    --pretrained_model $MODEL_PATH/caffe/yolov3/416/yolov3_416.caffemodel \
    --net_input_dims 416,416 \
    --obj_threshold 0.005 \
    --nms_threshold 0.45 \
    --dataset=$DATASET_PATH/coco/val2017 \
    --annotations=$DATASET_PATH/coco/annotations/instances_val2017.json \
    --result_json=result_416.json
    --count=100

$ eval_caffe_detector_yolo.py \
    --model_def $MODEL_PATH/caffe/yolov3/608/yolov3_608.prototxt \
    --pretrained_model $MODEL_PATH/caffe/yolov3/608/yolov3_608.caffemodel \
    --net_input_dims 608,608 \
    --obj_threshold 0.005 \
    --nms_threshold 0.45 \
    --dataset=$DATASET_PATH/coco/val2017 \
    --annotations=$DATASET_PATH/coco/annotations/instances_val2017.json \
    --result_json=result_608.json \
    --count=100
```
